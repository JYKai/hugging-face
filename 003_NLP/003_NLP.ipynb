{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f55f9f30-e5f7-4d9f-89e2-cc6e555d123f",
   "metadata": {},
   "source": [
    "# Text Classificaiton: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c088b7c-39f7-451f-ac6b-b9da859b85b5",
   "metadata": {},
   "source": [
    "**텍스트 분류(Text classificaiton)** 는 입력 테스트를 미리 정의된 범주나 레이블로 할당하는 과제를 의미한다.\n",
    "\n",
    "**BERT(Bidirectional Encoder Representations form Transformers)** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de36ca-3dcb-42dd-9f64-81c419c6595b",
   "metadata": {},
   "source": [
    "## BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7002af-65d7-4bbb-9ee4-85b367f21bf6",
   "metadata": {},
   "source": [
    "BERT는 워드피스 토크나이저를 사용한다.\n",
    "- 워드피스 : 단어를 더 작은 서브워드 단위로 나누는 방식\n",
    "    - OOV 문제 완화\n",
    "    - 데이터 기반으로 토큰 집합 생성 -> 도메인 적응성 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28149c-594e-4f20-9be1-97d11e06e1f0",
   "metadata": {},
   "source": [
    "**Tokenization using BERT Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755c71ea-127d-40e2-8223-c6e3c22b7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78359ecf-77dc-406f-a565-e938f2f67397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a167cc8e3e64e0c829b59fe32d40974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc8f9a434574be89292e105e5c9ad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4960cf4ca5214377bb3c7b6dedca79df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03ac5eb974b431381ead29c8a87f4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5b022d-1ddc-4bf4-8954-6c059699d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Transformers Is so COOL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3f7ade-b17b-495d-a521-904b02f319e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 58263, 10127, 10297, 26462, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b9ad1-2114-4a5a-8a40-47097422f6ae",
   "metadata": {},
   "source": [
    "- `input_ids` : 입력 텍스트를 정수 인코딩으로 변환한 값\n",
    "- `token_type_ids` : 입력이 여러 세그먼트로 구성된 경우 각 세그먼트를 구분하는 값\n",
    "- `attention_mask` : 트랜스포머 인코더의 셀프 어텐션에 사용되는 마스크 값, 모델이 어떤 토큰을 무시해야 하는지를 지정하는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e365bcec-e00d-4e23-bc5c-00f1301aeeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:27:47.670046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-03 23:27:47.772344: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-03 23:27:47.776119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-03 23:27:47.776129: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-11-03 23:27:47.795118: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-03 23:27:48.378190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-03 23:27:48.378238: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-03 23:27:48.378244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] transformers is so cool [SEP]\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded[\"input_ids\"]\n",
    "decoded = tokenizer.decode(input_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f5aaa-397a-40af-b0ac-f122a2bb83d0",
   "metadata": {},
   "source": [
    "- 전처리 단계에서 모든 문자를 소문자로 변환\n",
    "    - 동일한 단어가 대소문자로 인해 다르게 표기되는 문제 해결 -> 데이터 일관성 확보\n",
    "    - 대소문자를 구분하지 않으므로 어휘 사전의 크기 감소 -> 계산 효율성 향상\n",
    "    - 개체명 인식 등 대소문자 구분이 중요한 과제에서는 성능이 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63a2e8-2524-436c-aab8-aea9ef216c98",
   "metadata": {},
   "source": [
    "## BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefc062-7243-4f2b-9c44-8c1eb14ee860",
   "metadata": {},
   "source": [
    "1. 임베딩 계층\n",
    "    - 입력 텍스트를 벡터 형태로 변환하는 역할\n",
    "2. 인코더 계층\n",
    "    - 12개의 트랜스포머 인코더 계층으로 구성\n",
    "3. 풀러 계층\n",
    "    - 인코더 계층의 최종 출력을 받아 [CLS] 토큰의 벡터를 추출하고 이를 요약벡터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f98b7-070f-4f6c-a7b5-85868f42888f",
   "metadata": {},
   "source": [
    "**Structure of BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e78cef-73ad-48f0-b502-47622e6895a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ed25fd-17ff-4fad-8098-890c50ecdf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e72132000946d8bfd416c5a80f7d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de53f3d6-77cf-4471-852d-4fb77cd8897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main name =  embeddings\n",
      "L word_embeddings\n",
      "L position_embeddings\n",
      "L token_type_embeddings\n",
      "L LayerNorm\n",
      "L dropout\n",
      "Main name =  encoder\n",
      "L layer\n",
      "| L 0\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 1\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 2\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 3\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 4\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 5\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 6\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 7\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 8\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 9\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 10\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "| L 11\n",
      "| | L attention\n",
      "| | L intermediate\n",
      "| | L output\n",
      "Main name =  pooler\n",
      "L dense\n",
      "L activation\n"
     ]
    }
   ],
   "source": [
    "for main_name, main_module in model.named_children():\n",
    "    print(\"Main name = \", main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"L\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"| L\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"| | L\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c019c36-599b-4181-b4f8-68d63d05c0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
